{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPemz8UYnsWLQ/Q7FzsVHbK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustaFTW/TensorFlow-ZTM/blob/main/section8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to NLP Fundamentals in TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences of text or speech)\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ],
      "metadata": {
        "id": "HsLp6zIweh1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for GPU"
      ],
      "metadata": {
        "id": "YpU8gM8leyzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bli_HEe8e7Jq",
        "outputId": "3454ec27-c861-4833-e375-802f1c6bec40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-fe65cd04-062e-b58f-2eff-d0015a5b74e3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get helper functions"
      ],
      "metadata": {
        "id": "0N5FXpe_fB7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "gyaCp189fICj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c78a8f-2b54-4e54-96e8-1afe22473c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-20 14:08:00--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-20 14:08:00 (100 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaster os not disaster).\n",
        "\n",
        "See original source: https://www.kaggle.com/competitions/nlp-getting-started/data"
      ],
      "metadata": {
        "id": "ybAMUsZffMUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5rLTMqrfkAf",
        "outputId": "bed46481-0941-419b-9382-851dbd97b318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-20 14:08:07--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.62.128, 172.253.115.128, 172.253.122.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.62.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2023-01-20 14:08:07 (76.1 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do so would be to use Python\n",
        "\n",
        "\n",
        "But I prefer to get visual straight away.\n",
        "\n",
        "So another way to do this is to use pandas..."
      ],
      "metadata": {
        "id": "J69QfntPgccf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oBAxwznQgf5_",
        "outputId": "12254ec5-d3bd-4b89-b886-e9b21a8621c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b853cbbb-ffa8-4ff9-9a09-c94d8a663863\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b853cbbb-ffa8-4ff9-9a09-c94d8a663863')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b853cbbb-ffa8-4ff9-9a09-c94d8a663863 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b853cbbb-ffa8-4ff9-9a09-c94d8a663863');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=69)\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wrM5LwJChKjo",
        "outputId": "c882df46-1e66-4dc3-91ec-27183bb31e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id             keyword            location  \\\n",
              "421    611            arsonist  [ Blonde Bi Fry. ]   \n",
              "5047  7195  natural%20disaster               home    \n",
              "5046  7194            mudslide                 NaN   \n",
              "1881  2702               crush                 NaN   \n",
              "6543  9362            survived                 NaN   \n",
              "\n",
              "                                                   text  target  \n",
              "421                         'wHeRE's mY aRsOnISt aT???'       0  \n",
              "5047  she's a natural disaster she's the last of the...       0  \n",
              "5046  @nikistitz even the one that looked like a mud...       0  \n",
              "1881                        kenny holland crush da vida       0  \n",
              "6543  Not one character in the final destination ser...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f92a6929-54c0-40cf-be6d-41225b696620\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>611</td>\n",
              "      <td>arsonist</td>\n",
              "      <td>[ Blonde Bi Fry. ]</td>\n",
              "      <td>'wHeRE's mY aRsOnISt aT???'</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5047</th>\n",
              "      <td>7195</td>\n",
              "      <td>natural%20disaster</td>\n",
              "      <td>home</td>\n",
              "      <td>she's a natural disaster she's the last of the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5046</th>\n",
              "      <td>7194</td>\n",
              "      <td>mudslide</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@nikistitz even the one that looked like a mud...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1881</th>\n",
              "      <td>2702</td>\n",
              "      <td>crush</td>\n",
              "      <td>NaN</td>\n",
              "      <td>kenny holland crush da vida</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6543</th>\n",
              "      <td>9362</td>\n",
              "      <td>survived</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Not one character in the final destination ser...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f92a6929-54c0-40cf-be6d-41225b696620')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f92a6929-54c0-40cf-be6d-41225b696620 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f92a6929-54c0-40cf-be6d-41225b696620');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcuA6QdyhZhW",
        "outputId": "6ee4e6de-242e-4ef3-d3bd-bcb68551bb7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many total samples?\n",
        "len(train_df) + len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P2OyNWWiTTT",
        "outputId": "01498b77-05bd-48ee-c800-a17fe57fbf7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10876"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "number_samples = 3\n",
        "random_index = random.randint(0, len(train_df)-number_samples)\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+number_samples].itertuples():\n",
        "    _, text, target = row\n",
        "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "    print(f\"Text:\\n{text}\\n\")\n",
        "    print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzN1JIdhizoG",
        "outputId": "95b4ff5a-c448-4ec6-c200-d32a1a0c4180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Man Currensy really be talkin that talk... I'd be more devastated if he had a ghostwriter than anybody else....\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Ugh So hungry I'm going to demolish this food!\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Obama Declares Disaster for Typhoon-Devastated Saipan: Obama signs disaster declaration for Northern Marians a... http://t.co/BHZr9UgUs2\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data into training and validation sets"
      ],
      "metadata": {
        "id": "0_mNdcwdj7H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "pZX6XWsPkyXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # use 10% of training data for validation split\n",
        "                                                                            random_state=69)"
      ],
      "metadata": {
        "id": "ram2zxfDk-gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the  lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9LuuTrOleYx",
        "outputId": "b16153d9-3988-4e1b-9a2d-0015a5976857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first 10 examples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-87Vm2hlnIW",
        "outputId": "5802029c-80fe-41a2-ff49-58c6d2644afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@ChrisDanielShow Nearly-Fatal Pee in San Francisco http://t.co/1tvlFrhm1m',\n",
              "        \"babe I'm gonna ruin you if you let me stay\",\n",
              "        \"We're happily collided :)\",\n",
              "        \"RT THR 'RT THRArchives: 1928: When Leo the MGM Lion Survived a Plane Crash #TBT http://t.co/Wpkl2qNiQW http://t.co/BD52FxDvhQ'\",\n",
              "        '@FoxNews let me report it to u people instead Mr.Obama just declares CNMI federal disaster area post typhoon soudelor. U guys 2slow2report.',\n",
              "        \"Don't say @ALIPAPER: women got problems this #keepingtheviginaclean thing is very interesting n less expensive #metrofmtalk'\",\n",
              "        \"'Jet fuel cant melt steel'\\n'The structural failure is illogical'\\n'The second plane crashing into the building is fake'\\n'It was a bomb'\",\n",
              "        'A grade in Black Horse Famine[MEGA]. Score 0840728\\nhttp://t.co/pdiit0AF3Q\\n#Dynamix http://t.co/ZQ5KDOx7BY',\n",
              "        'Even when I was a kid haha super late but folks used to bash me for that shit I understand he survived cancer but he still cheated',\n",
              "        '@montetjwitter11 @nolesfan05 @NutsAndBoltsSP I say concern but not panic. Too many games left. And some games left against each other.'],\n",
              "       dtype=object), array([0, 0, 0, 1, 1, 0, 1, 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first trhings you'll have to do before you can build a model is to converty your text to number.\n",
        "\n",
        "there are a few ways to do this, namely:\n",
        "* Tokenziation - directo mapping of token (a token could be a word or a character) to number\n",
        "* Embedding - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)"
      ],
      "metadata": {
        "id": "8vZJcQO_lt3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text vectorization (tokenization)"
      ],
      "metadata": {
        "id": "PB40oF28mKYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t98ULYNhpUdV",
        "outputId": "24b8a3b9-1094-4b75-d643-2e8ad4e2d686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@ChrisDanielShow Nearly-Fatal Pee in San Francisco http://t.co/1tvlFrhm1m',\n",
              "       \"babe I'm gonna ruin you if you let me stay\",\n",
              "       \"We're happily collided :)\",\n",
              "       \"RT THR 'RT THRArchives: 1928: When Leo the MGM Lion Survived a Plane Crash #TBT http://t.co/Wpkl2qNiQW http://t.co/BD52FxDvhQ'\",\n",
              "       '@FoxNews let me report it to u people instead Mr.Obama just declares CNMI federal disaster area post typhoon soudelor. U guys 2slow2report.',\n",
              "       \"Don't say @ALIPAPER: women got problems this #keepingtheviginaclean thing is very interesting n less expensive #metrofmtalk'\",\n",
              "       \"'Jet fuel cant melt steel'\\n'The structural failure is illogical'\\n'The second plane crashing into the building is fake'\\n'It was a bomb'\",\n",
              "       'A grade in Black Horse Famine[MEGA]. Score 0840728\\nhttp://t.co/pdiit0AF3Q\\n#Dynamix http://t.co/ZQ5KDOx7BY',\n",
              "       'Even when I was a kid haha super late but folks used to bash me for that shit I understand he survived cancer but he still cheated',\n",
              "       '@montetjwitter11 @nolesfan05 @NutsAndBoltsSP I say concern but not panic. Too many games left. And some games left against each other.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=10000, # how many words in the vocabulary (automatically add <OOV>)\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None, # create groups of n-words\n",
        "                                    output_mode=\"int\", # how to map tokens into numbers\n",
        "                                    output_sequence_length=None, # how long do you want your sequences to be?\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "metadata": {
        "id": "sFZPeBLfpWRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average number of tokens (words) in the trianing tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/ len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF4jwW2BpcU-",
        "outputId": "91a57db5-511d-4635-f548-8f13861c8716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does a model see)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "pjY4AZvJsp5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Fit the text vectorizer to the training text \n",
        " text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "k9h6-tTMtS7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocIHtpIbt52R",
        "outputId": "9d25e47f-7b85-4162-bfe8-9929b7a7b1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@ChrisDanielShow Nearly-Fatal Pee in San Francisco http://t.co/1tvlFrhm1m',\n",
              "       \"babe I'm gonna ruin you if you let me stay\",\n",
              "       \"We're happily collided :)\",\n",
              "       \"RT THR 'RT THRArchives: 1928: When Leo the MGM Lion Survived a Plane Crash #TBT http://t.co/Wpkl2qNiQW http://t.co/BD52FxDvhQ'\",\n",
              "       '@FoxNews let me report it to u people instead Mr.Obama just declares CNMI federal disaster area post typhoon soudelor. U guys 2slow2report.',\n",
              "       \"Don't say @ALIPAPER: women got problems this #keepingtheviginaclean thing is very interesting n less expensive #metrofmtalk'\",\n",
              "       \"'Jet fuel cant melt steel'\\n'The structural failure is illogical'\\n'The second plane crashing into the building is fake'\\n'It was a bomb'\",\n",
              "       'A grade in Black Horse Famine[MEGA]. Score 0840728\\nhttp://t.co/pdiit0AF3Q\\n#Dynamix http://t.co/ZQ5KDOx7BY',\n",
              "       'Even when I was a kid haha super late but folks used to bash me for that shit I understand he survived cancer but he still cheated',\n",
              "       '@montetjwitter11 @nolesfan05 @NutsAndBoltsSP I say concern but not panic. Too many games left. And some games left against each other.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uml4l_lzt7Nb",
        "outputId": "683b977f-f5e1-4259-bc45-bec2bfa1ecb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[257,   3, 239,   5,  13, 702,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "        \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTmoODL9uJZZ",
        "outputId": "754f17eb-5820-4386-fdb3-431e1abf005b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "The cool kids asked me if I wanted to hang out after school so I had a panic attack and had to go to the hospital #autismawareness        \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   2,  526,  516, 1735,   26,   45,    8, 1028,    4, 2994,   36,\n",
              "          41,  179,   27,    8]])>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "words_in_vocab[:5] # get the most common words\n",
        "words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words: {words_in_vocab[:10]}\")\n",
        "print(f\"5 least common words: {words_in_vocab[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaE6tDcsuzX1",
        "outputId": "74b64b25-65a5-4a6d-d2cd-1e07b2142501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'to', 'in', 'of', 'and', 'i', 'is']\n",
            "5 least common words: ['panicked', 'pandora', 'pandemoniumiso', 'pandemic', 'panda']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an Embedding using an Embedding layer\n",
        "\n",
        "To make our embedding, we're going to use TensorFlow's embedding layer\n",
        "\n",
        "The parameters we care most about for our embedding layer:\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented as a vector 100 long\n",
        "* `input_length` = length of the sequences being passed to the embedding layer"
      ],
      "metadata": {
        "id": "q6X_rYXTwG_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = tf.keras.layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # output shape,\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=max_length # how long is each input\n",
        "                             )\n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj8j7ySYxIXP",
        "outputId": "ea42edb3-d048-4027-d439-9f54a607d98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f81100e06a0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "        \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmxB67drysOR",
        "outputId": "5934497b-ff07-40c5-b7af-db3612dcb8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " I was in a horrible car accident this past Sunday. I'm finally able to get around. Thank you GOD??        \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.00958958, -0.01776352,  0.02393601, ...,  0.02883032,\n",
              "          0.04363749, -0.02646998],\n",
              "        [ 0.01479634,  0.02544777,  0.04169513, ...,  0.02023281,\n",
              "          0.01929759,  0.01687864],\n",
              "        [ 0.02153952,  0.04665888,  0.00413417, ..., -0.01364823,\n",
              "          0.00702504, -0.00481465],\n",
              "        ...,\n",
              "        [ 0.04010587,  0.03562632, -0.03427448, ...,  0.02622775,\n",
              "         -0.03557865, -0.03935429],\n",
              "        [-0.02902803,  0.04448882,  0.0252008 , ...,  0.04356781,\n",
              "         -0.03129878,  0.01464598],\n",
              "        [-0.01849232,  0.03950007, -0.02708852, ..., -0.00439485,\n",
              "          0.01647099,  0.01514309]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTKT4GCPz4Hb",
        "outputId": "061594af-ee92-41a4-adb7-1fa6e0c28b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.00958958, -0.01776352,  0.02393601,  0.00878153,  0.0195506 ,\n",
              "        -0.00229176, -0.00478513, -0.02452946,  0.00194732,  0.01259555,\n",
              "         0.00474857, -0.02624936,  0.02237291, -0.02633213, -0.0396691 ,\n",
              "         0.04433174, -0.02575672,  0.03926647, -0.03960979, -0.02139329,\n",
              "        -0.0408328 ,  0.04421889, -0.03518897, -0.03560494, -0.00259489,\n",
              "         0.04302828,  0.02674792, -0.01832313,  0.01587128, -0.01029665,\n",
              "         0.01948318, -0.02689917, -0.04281396,  0.01000056, -0.0488076 ,\n",
              "         0.00956049, -0.03409134, -0.04747262,  0.00970721, -0.03773642,\n",
              "        -0.02471132, -0.00240294, -0.00766774,  0.04968861, -0.04410336,\n",
              "         0.02768162,  0.00922175, -0.01874187, -0.04762753,  0.03857002,\n",
              "         0.04166759,  0.02272904,  0.0415164 ,  0.02033942,  0.00637997,\n",
              "         0.04268363,  0.02369162, -0.01579813,  0.04327616,  0.04946462,\n",
              "         0.03028542, -0.03485493,  0.04363028,  0.00844611,  0.0259507 ,\n",
              "         0.03246531,  0.03396295, -0.02482467,  0.04144024,  0.00722176,\n",
              "         0.02846164,  0.01885909, -0.04082451,  0.02741823,  0.04823563,\n",
              "        -0.03207029, -0.0442228 , -0.0480466 ,  0.03345585, -0.02906393,\n",
              "         0.03143925,  0.03672253, -0.02322035, -0.03464216,  0.04605624,\n",
              "         0.0161924 , -0.02733827, -0.02029003, -0.00965847, -0.03378767,\n",
              "        -0.01762966, -0.04839981,  0.03493119, -0.04030299,  0.01785033,\n",
              "        -0.02827404,  0.02970165,  0.03050346,  0.02684617, -0.04017724,\n",
              "         0.00186483,  0.00713418,  0.04425151, -0.01231869, -0.03305177,\n",
              "         0.00377917, -0.02179906, -0.04963223,  0.04547398, -0.0072005 ,\n",
              "        -0.01590567, -0.04832062, -0.04109542, -0.01763809,  0.04556351,\n",
              "         0.02119774,  0.02570956, -0.04164957, -0.02979348, -0.01520044,\n",
              "        -0.00963308,  0.01113957, -0.00703984,  0.00632012,  0.02714228,\n",
              "         0.02883032,  0.04363749, -0.02646998], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " \"I was in a horrible car accident this past Sunday. I'm finally able to get around. Thank you GOD??\")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "\n",
        "Now we've got a way to turn our text sequences into numbers, it's time to start building a series of modelling experiments.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTMmodel (RNN)\n",
        "* Model 3: GRU model (RNN)\n",
        "* Model 4: Bidirectional-LSTM model (RNN)\n",
        "* Model 5: 1D Convolutional Neural Network (CNN)\n",
        "* Model 6: TensorFlow Hub Pretrained Featre Extractor (using transfer learning for NLP)\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "How are we going to approach all of these?\n",
        "\n",
        "Use the standard steps in modelling with tensorflow:\n",
        "\n",
        "* Create a model\n",
        "* Build a model\n",
        "* Fit a model\n",
        "* Evaluate our model"
      ],
      "metadata": {
        "id": "7_VVWL740LV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll use Sklearn's Multinomial Naive Bayes using the TF-IDF formula to convert our words to numbers.\n",
        "\n",
        "> **Note:** It's common practice to use non-DL algorithms as a baseline because of their spped and then later using DL to see if you can improve upon them."
      ],
      "metadata": {
        "id": "66xzrwHrguS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCDDi5OljYSN",
        "outputId": "8d20db1f-c18f-466f-e0da-bc95eb222f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnJh1YFDkT5y",
        "outputId": "d853a85d-1053-48f9-ec34-a1f9d3337135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9FjENj8k4YC",
        "outputId": "01c2bee3-fe90-447d-85c0-1547055701a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "Let's make a function to evaluate our modelling experiment predictions using:\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ],
      "metadata": {
        "id": "zaYLNG34k80D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate model accuracy\n",
        "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "    # Calculate model precision, recall and f1-score using \"weighted\" average\n",
        "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    model_results = {\"accuracy\": model_accuracy,\n",
        "                     \"precision\": model_precision,\n",
        "                     \"recall\": model_recall,\n",
        "                     \"f1\": model_f1}\n",
        "    return model_results"
      ],
      "metadata": {
        "id": "KiRXN8HqlxZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(val_labels, baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmiEIJtwpI-s",
        "outputId": "2babf12f-cbed-482f-bf3c-fc8558611277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.79002624671917,\n",
              " 'precision': 0.8049118114708822,\n",
              " 'recall': 0.7979002624671916,\n",
              " 'f1': 0.7932923017133588}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: A simple dense model"
      ],
      "metadata": {
        "id": "tj81CVCepPfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save Tensorboard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "ECUzf5g0qOXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers \n",
        "x = embedding(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
      ],
      "metadata": {
        "id": "yU8AAZhmsUBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1 = model_1.fit(train_sentences,\n",
        "                        train_labels, \n",
        "                        epochs=5,\n",
        "                        validation_data=(val_sentences, val_labels),\n",
        "                        callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                               experiment_name=\"model_1_dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8vAoEzrrSVL",
        "outputId": "70f657fe-2451-40a4-daaa-6bf00c6edd27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20230120-150048\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 6ms/step - loss: 0.6119 - accuracy: 0.6919 - val_loss: 0.5313 - val_accuracy: 0.7598\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.4417 - accuracy: 0.8162 - val_loss: 0.4707 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.3470 - accuracy: 0.8610 - val_loss: 0.4596 - val_accuracy: 0.7940\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2829 - accuracy: 0.8902 - val_loss: 0.4693 - val_accuracy: 0.7913\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2355 - accuracy: 0.9120 - val_loss: 0.4889 - val_accuracy: 0.7782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRCBKmk8shba",
        "outputId": "b4c517ff-953c-4c77-b606-1ca26b4579c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 9ms/step - loss: 0.4889 - accuracy: 0.7782\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4889427423477173, 0.778215229511261]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmxBKRjkskrl",
        "outputId": "09668afa-dcdd-42a9-d2c3-3eec68a14d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at a single prediction\n",
        "model_1_pred_probs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLRUeIKbsq_f",
        "outputId": "3a58fa72-db11-471b-c42e-2388686f1528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.94225055], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the first 10\n",
        "model_1_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tArnEZPQuWHI",
        "outputId": "1499060b-b0bf-4344-acb5-c7319dc98278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.94225055],\n",
              "       [0.5889235 ],\n",
              "       [0.04023167],\n",
              "       [0.02157172],\n",
              "       [0.1572312 ],\n",
              "       [0.96717256],\n",
              "       [0.97165316],\n",
              "       [0.03744039],\n",
              "       [0.12288823],\n",
              "       [0.99855274]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlnM-kp2uZpI",
        "outputId": "08670879-1fab-4a12-a517-fa720fb1d4ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate our model_1 reulsts\n",
        "model_1_results = calculate_results(val_labels,\n",
        "                                    model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3p8-U2wugNr",
        "outputId": "11efa531-e48d-4666-a142-86b4cb40de4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'precision': 0.7775276018850527,\n",
              " 'recall': 0.7782152230971129,\n",
              " 'f1': 0.7775654664384112}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6aTtpGEu6WX",
        "outputId": "01714ef8-8c11-49c3-d00a-30361fe9557c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.79002624671917,\n",
              " 'precision': 0.8049118114708822,\n",
              " 'recall': 0.7979002624671916,\n",
              " 'f1': 0.7932923017133588}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV7zjkb9u8Wg",
        "outputId": "506e0052-3e23-44ca-f175-65b0bbb3f905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "ZcZcrgH4vCVo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}